[
  {
    "role": "system",
    "content": [
      {
        "type": "text",
        "text": "The following is metadata about Dandiset 001433 version 0.250507.2356."
      },
      {
        "type": "text",
        "text": "{\n  \"id\": \"DANDI:001433/0.250507.2356\",\n  \"doi\": \"10.48324/dandi.001433/0.250507.2356\",\n  \"url\": \"https://dandiarchive.org/dandiset/001433/0.250507.2356\",\n  \"name\": \"Breathing rhythm and place dataset\",\n  \"about\": [],\n  \"access\": [\n    {\n      \"status\": \"dandi:OpenAccess\",\n      \"schemaKey\": \"AccessRequirements\"\n    }\n  ],\n  \"license\": [\n    \"spdx:CC-BY-4.0\"\n  ],\n  \"version\": \"0.250507.2356\",\n  \"@context\": \"https://raw.githubusercontent.com/dandi/schema/master/releases/0.6.9/context.json\",\n  \"citation\": \"Breathing rhythm and place dataset (2025). (Version 0.250507.2356) [Data set]. DANDI Archive. https://doi.org/10.48324/dandi.001433/0.250507.2356\",\n  \"schemaKey\": \"Dandiset\",\n  \"identifier\": \"DANDI:001433\",\n  \"repository\": \"https://dandiarchive.org\",\n  \"contributor\": [\n    {\n      \"name\": \"National Institutes of Health (NIH)\",\n      \"roleName\": [\n        \"dcite:Funder\"\n      ],\n      \"schemaKey\": \"Organization\",\n      \"awardNumber\": \"1 R01 NS 123903-03\"\n    },\n    {\n      \"name\": \"Smear, Matt\",\n      \"email\": \"smear@uoregon.edu\",\n      \"roleName\": [\n        \"dcite:ContactPerson\",\n        \"dcite:Author\",\n        \"dcite:Conceptualization\",\n        \"dcite:DataCurator\",\n        \"dcite:DataManager\"\n      ],\n      \"schemaKey\": \"Person\",\n      \"identifier\": \"0000-0003-4689-388X\"\n    }\n  ],\n  \"dateCreated\": \"2025-05-05T18:39:37.730571+00:00\",\n  \"description\": \"These are behavioral and electrophysiological data from recordings of sniffing, video, and OB electrophysiology in freely-behaving mice given no stimulus, reward, or task. 1 1 R01 NS 123903\",\n  \"publishedBy\": {\n    \"id\": \"urn:uuid:b6ac97aa-3293-4dbe-a7b5-71ab54c1232e\",\n    \"name\": \"DANDI publish\",\n    \"endDate\": \"2025-05-07T23:56:47.954574+00:00\",\n    \"schemaKey\": \"PublishActivity\",\n    \"startDate\": \"2025-05-07T23:56:47.954574+00:00\",\n    \"wasAssociatedWith\": [\n      {\n        \"id\": \"urn:uuid:e47c3249-bd09-40ab-aa88-74f6e2c6f668\",\n        \"name\": \"DANDI API\",\n        \"version\": \"0.1.0\",\n        \"schemaKey\": \"Software\",\n        \"identifier\": \"RRID:SCR_017571\"\n      }\n    ]\n  },\n  \"assetsSummary\": {\n    \"species\": [\n      {\n        \"name\": \"Mus musculus - House mouse\",\n        \"schemaKey\": \"SpeciesType\",\n        \"identifier\": \"http://purl.obolibrary.org/obo/NCBITaxon_10090\"\n      }\n    ],\n    \"approach\": [\n      {\n        \"name\": \"electrophysiological approach\",\n        \"schemaKey\": \"ApproachType\"\n      }\n    ],\n    \"schemaKey\": \"AssetsSummary\",\n    \"dataStandard\": [\n      {\n        \"name\": \"Neurodata Without Borders (NWB)\",\n        \"schemaKey\": \"StandardsType\",\n        \"identifier\": \"RRID:SCR_015242\"\n      }\n    ],\n    \"numberOfBytes\": 41430354280,\n    \"numberOfFiles\": 27,\n    \"numberOfSubjects\": 4,\n    \"variableMeasured\": [\n      \"ProcessingModule\",\n      \"ElectricalSeries\",\n      \"ElectrodeGroup\"\n    ],\n    \"measurementTechnique\": [\n      {\n        \"name\": \"surgical technique\",\n        \"schemaKey\": \"MeasurementTechniqueType\"\n      },\n      {\n        \"name\": \"multi electrode extracellular electrophysiology recording technique\",\n        \"schemaKey\": \"MeasurementTechniqueType\"\n      },\n      {\n        \"name\": \"analytical technique\",\n        \"schemaKey\": \"MeasurementTechniqueType\"\n      }\n    ]\n  },\n  \"datePublished\": \"2025-05-07T23:56:47.954574+00:00\",\n  \"schemaVersion\": \"0.6.9\",\n  \"ethicsApproval\": [],\n  \"wasGeneratedBy\": [],\n  \"relatedResource\": [],\n  \"manifestLocation\": [\n    \"https://dandiarchive.s3.amazonaws.com/dandisets/001433/0.250507.2356/assets.yaml\"\n  ]\n}"
      }
    ]
  },
  {
    "role": "system",
    "content": [
      {
        "type": "text",
        "text": "The following is a listing of some of the files in the Dandiset."
      },
      {
        "type": "text",
        "text": "sub-4122/sub-4122_ses-20250507T152927_ecephys.nwb\nsub-4122/sub-4122_ses-20250507T152930_ecephys.nwb\nsub-4122/sub-4122_ses-20250507T152933_ecephys.nwb\nsub-4127/sub-4127_ses-20250507T152941_ecephys.nwb\nsub-4127/sub-4127_ses-20250507T152953_ecephys.nwb\nsub-4127/sub-4127_ses-20250507T153010_ecephys.nwb\nsub-4127/sub-4127_ses-20250507T153020_ecephys.nwb\nsub-4127/sub-4127_ses-20250507T153032_ecephys.nwb\nsub-4127/sub-4127_ses-20250507T153048_ecephys.nwb\nsub-4127/sub-4127_ses-20250507T153100_ecephys.nwb"
      }
    ]
  },
  {
    "role": "system",
    "content": [
      {
        "type": "text",
        "text": "The following is metadata and usage information about the file sub-4122/sub-4122_ses-20250507T152927_ecephys.nwb."
      },
      {
        "type": "text",
        "text": "\nimport pynwb\nimport h5py\nimport remfile\n\n# Load\nfrom dandi.dandiapi import DandiAPIClient\n\nclient = DandiAPIClient()\ndandiset = client.get_dandiset(\"001433\", \"0.250507.2356\")\nurl = next(dandiset.get_assets_by_glob(\"sub-4122/sub-4122_ses-20250507T152927_ecephys.nwb\")).download_url\n\nremote_file = remfile.File(url)\nh5_file = h5py.File(remote_file)\nio = pynwb.NWBHDF5IO(file=h5_file)\nnwb = io.read()\n\nnwb # (NWBFile)\nnwb.session_description # (str) LFP and sniff recording\nnwb.identifier # (str) 4122_4\nnwb.session_start_time # (datetime) 2025-05-07T15:29:27.359523-07:00\nnwb.timestamps_reference_time # (datetime) 2025-05-07T15:29:27.359523-07:00\nnwb.file_create_date # (list) [datetime.datetime(2025, 5, 7, 15, 29, 27, 359523, tzinfo=tzoffset(None, -25200))]\nnwb.experimenter # (tuple) ['Rafilson, Sidney']\nnwb.acquisition # (LabelledDict)\nacquisition = nwb.acquisition\nLFP = acquisition[\"LFP\"]\nLFP # (ElectricalSeries)\nLFP.starting_time # (float64) 0.0\nLFP.rate # (float64) 1000.0\nLFP.resolution # (float64) -1.0\nLFP.comments # (str) no comments\nLFP.description # (str) LFP signal from olfactory bulb\nLFP.conversion # (float64) 1.0\nLFP.offset # (float64) 0.0\nLFP.unit # (str) volts\nLFP.data # (Dataset) shape (1969184, 16); dtype float64\n# LFP.data[:, :] # Access all data\n# LFP.data[0:n, :] # Access first n rows\n# LFP.data[:, 0:n] # Access first n columns\nLFP.starting_time_unit # (str) seconds\nLFP.electrodes # (DynamicTableRegion)\nLFP.electrodes.description # (str) All LFP electrodes\nLFP.electrodes.table # (DynamicTable)\nLFP.electrodes.table.description # (str) metadata about extracellular electrodes\nLFP.electrodes.table.colnames # (tuple) ['location', 'group', 'group_name', 'filtering']\nLFP.electrodes.table.columns # (tuple)\nLFP.electrodes.table.id # (ElementIdentifiers)\n# LFP.electrodes.table.to_dataframe() # (DataFrame) Convert to a pandas DataFrame with 16 rows and 4 columns\n# LFP.electrodes.table.to_dataframe().head() # (DataFrame) Show the first few rows of the pandas DataFrame\nLFP.electrodes.table.location # (VectorData) the location of channel within the subject e.g. brain region\nLFP.electrodes.table.group # (VectorData) a reference to the ElectrodeGroup this electrode is a part of\nLFP.electrodes.table.group_name # (VectorData) the name of the ElectrodeGroup this electrode is a part of\nLFP.electrodes.table.filtering # (VectorData) description of hardware filtering, including the filter name and frequency cutoffs\nSniffSignal = acquisition[\"SniffSignal\"]\nSniffSignal # (TimeSeries)\nSniffSignal.starting_time # (float64) 0.0\nSniffSignal.rate # (float64) 1000.0\nSniffSignal.resolution # (float64) -1.0\nSniffSignal.comments # (str) no comments\nSniffSignal.description # (str) Raw sniff thermistor voltage\nSniffSignal.conversion # (float64) 1.0\nSniffSignal.offset # (float64) 0.0\nSniffSignal.unit # (str) volts\nSniffSignal.data # (Dataset) shape (1969184,); dtype float64\n# SniffSignal.data[:] # Access all data\n# SniffSignal.data[0:n] # Access first n elements\nSniffSignal.starting_time_unit # (str) seconds\nnwb.keywords # (StrDataset) shape (5,); dtype object\n# nwb.keywords[:] # Access all data\n# nwb.keywords[0:n] # Access first n elements\n# First few values of nwb.keywords: ['olfactory bulb' 'LFP' 'sniffing' 'mouse' 'neuroscience']\nnwb.processing # (LabelledDict)\nprocessing = nwb.processing\nbehavior = processing[\"behavior\"]\nbehavior # (ProcessingModule)\nbehavior.description # (str) Sniff event features\nbehavior.data_interfaces # (LabelledDict)\ndata_interfaces = behavior.data_interfaces\nexhalation_time = data_interfaces[\"exhalation_time\"]\nexhalation_time # (TimeSeries)\nexhalation_time.resolution # (float64) -1.0\nexhalation_time.comments # (str) no comments\nexhalation_time.description # (str) exhalation_time (s)\nexhalation_time.conversion # (float64) 1.0\nexhalation_time.offset # (float64) 0.0\nexhalation_time.unit # (str) NA\nexhalation_time.data # (Dataset) shape (10030,); dtype int64\n# exhalation_time.data[:] # Access all data\n# exhalation_time.data[0:n] # Access first n elements\nexhalation_time.timestamps # (Dataset) shape (10030,); dtype float64\n# exhalation_time.timestamps[:] # Access all data\n# exhalation_time.timestamps[0:n] # Access first n elements\nexhalation_time.timestamps_unit # (str) seconds\nexhalation_time.interval # (int) 1\ninhalation_time = data_interfaces[\"inhalation_time\"]\ninhalation_time # (TimeSeries)\ninhalation_time.resolution # (float64) -1.0\ninhalation_time.comments # (str) no comments\ninhalation_time.description # (str) inhalation_time (s)\ninhalation_time.conversion # (float64) 1.0\ninhalation_time.offset # (float64) 0.0\ninhalation_time.unit # (str) NA\ninhalation_time.data # (Dataset) shape (10030,); dtype int64\n# inhalation_time.data[:] # Access all data\n# inhalation_time.data[0:n] # Access first n elements\ninhalation_time.timestamps # (Dataset) shape (10030,); dtype float64\n# inhalation_time.timestamps[:] # Access all data\n# inhalation_time.timestamps[0:n] # Access first n elements\ninhalation_time.timestamps_unit # (str) seconds\ninhalation_time.interval # (int) 1\nnwb.electrode_groups # (LabelledDict)\nelectrode_groups = nwb.electrode_groups\nLFPGroup = electrode_groups[\"LFPGroup\"]\nLFPGroup # (ElectrodeGroup)\nLFPGroup.description # (str) LFP recording electrodes\nLFPGroup.location # (str) Olfactory Bulb\nLFPGroup.device # (Device)\nLFPGroup.device.description # (str) OpenEphys recording system\nnwb.devices # (LabelledDict)\ndevices = nwb.devices\nOpenEphys = devices[\"OpenEphys\"]\nOpenEphys # (Device)\nOpenEphys.description # (str) OpenEphys recording system\nnwb.experiment_description # (str) LFP and sniff behavior recording\nnwb.lab # (str) Smear lab\nnwb.institution # (str) University of Oregon\nnwb.electrodes # (DynamicTable)\nnwb.electrodes.description # (str) metadata about extracellular electrodes\nnwb.electrodes.colnames # (tuple) ['location', 'group', 'group_name', 'filtering']\nnwb.electrodes.columns # (tuple)\nnwb.electrodes.id # (ElementIdentifiers)\n# nwb.electrodes.to_dataframe() # (DataFrame) Convert to a pandas DataFrame with 16 rows and 4 columns\n# nwb.electrodes.to_dataframe().head() # (DataFrame) Show the first few rows of the pandas DataFrame\nnwb.electrodes.location # (VectorData) the location of channel within the subject e.g. brain region\nnwb.electrodes.group # (VectorData) a reference to the ElectrodeGroup this electrode is a part of\nnwb.electrodes.group_name # (VectorData) the name of the ElectrodeGroup this electrode is a part of\nnwb.electrodes.filtering # (VectorData) description of hardware filtering, including the filter name and frequency cutoffs\nnwb.subject # (Subject)\nnwb.subject.age # (str) P90D\nnwb.subject.age__reference # (str) birth\nnwb.subject.description # (str) Lab mouse used for sniffing + LFP experiment\nnwb.subject.sex # (str) M\nnwb.subject.species # (str) Mus musculus\nnwb.subject.subject_id # (str) 4122"
      }
    ]
  },
  {
    "role": "user",
    "content": "On the basis of the above information, please create a jupytext notebook that introduces dandiset 001433 using the format described below.\n\nThe purpose of the notebook is to help researchers explore the dandiset and get started with a reanalysis.\n\nStart with an appropriate title for the notebook, such as \"Exploring Dandiset 001433: ...\" (that should be a markdown heading).\n\nInform the user that the notebook was generated with the assistance of AI, and that they should be cautious when interpreting the code or results.\n\nProvide an overview of the Dandiset. Include a link to the Dandiset of the form https://dandiarchive.org/dandiset/001433/0.250507.2356.\n\nList the packages that are required to run the notebook. Assume that these are already installed on the user's system. Do not include any pip install commands in the notebook.\n\nShow how to use the DANDI Python API to information about the dandiset using code similar to the following:\n\nclient = DandiAPIClient()\ndandiset = client.get_dandiset(\"001333\", \"0.250327.2220\")\nmetadata = dandiset.get_raw_metadata()\nprint(f\"Dandiset name: {metadata['name']}\")\nprint(f\"Dandiset URL: {metadata['url']}\")\n\nShow how to use the DANDI Python API to explore the .nwb files in the dandiset.\n\nShow how to load and visualize data from the dandiset based on the above information.\n\n\n\nGenerate good quality plots (without being redundant).\n\nLoad NWB data by streaming the remote file (as done in the above information) rather than downloading it.\n\nDo not use any functionality of pynwb or dandi that is not covered in the above information.\n\n\n\nBe mindful of not loading too much data, considering that it will all be streamed from a remote source.\n\nThroughout the notebook, include explanatory markdown cells that guide the user through the process.\n\nThe notebook should be well-documented, and follow best practices Include comments in code cells to explain what each step does.\n\nThe Jupytext should use `# %% [markdown]` for markdown cells and `# %%` delimiters for the code cells.\n\nIf any NWB files have units objects, you should know the following:\nunits.spike_times_index[i] provides the vector of spike times for the i^th unit. It is actually not an index. Do not use units.spike_times.\n\nDo not render or display the nwb object obtained from NWBHDF5IO directly in the notebook as the output could be very large.\n\nUse concise scientific language.\n\nPrioritize correctness and accuracy over verbosity and complexity.\n\n\n\nDo not be verbose in your summary or wrap up of the notebook, although you may briefly suggest some general ideas for future exploration.\n\nThere is no need to close files or clean up resources at the end of the notebook.\n\nYour notebook will be evaluated based on the following criteria:\n1. How well did the notebook help you understand the purpose and content of the Dandiset?\n2. After reviewing the notebook, do you feel confident in how to access the different types of data from this Dandiset?\n3. Did the notebook help you understand the structure of the NWB file(s) and how to work with them?\n4. Did the visualizations in the notebook generally help you understand key aspects of the data?\n5. Did any of the visualizations make it harder to understand the data (e.g., due to poor formatting, unclear axes, or misleading displays)?\n6. Do you feel more confident creating your own visualizations of the data after seeing the examples in the notebook?\n7. How well did the visualizations show the structure or complexity of the data?\n8. Were there any interpretations or conclusions in the notebook that felt unclear or not well supported by the data shown?\n9. Did any of the plots or examples feel unnecessarily repetitive or redundant?\n10. Did the notebook help you understand what kinds of questions or analyses you could do next with this Dandiset?\n11. How clear and easy was the notebook to follow?\n12. Did the notebook provide code you could easily reuse or adapt to explore the Dandiset yourself?\n13. Did the notebook help you understand what kinds of questions or analyses you could do next with this Dandiset?\n14. Overall, how helpful was this notebook for getting started with this Dandiset?\n\nYour output must be in the format:\n\n<notebook>\nThe text of the jupytext notebook should appear here.\n</notebook>\n\nNo other text should be included in the response."
  },
  {
    "role": "assistant",
    "content": "<notebook>\n# %% [markdown]\n# # Exploring Dandiset 001433: Breathing rhythm and place dataset\n\n# %% [markdown]\n# **Note:** This notebook was generated with the assistance of AI. Please be cautious when interpreting the code or results, and verify findings independently.\n\n# %% [markdown]\n# ## Overview\n# \n# This dandiset contains behavioral and electrophysiological data from recordings of sniffing, video, and olfactory bulb (OB) electrophysiology in freely-behaving mice. The experiments were conducted without any stimulus, reward, or task, providing baseline measurements of neural activity and breathing patterns.\n# \n# **Dandiset URL:** https://dandiarchive.org/dandiset/001433/0.250507.2356\n# \n# The dataset includes:\n# - Local field potential (LFP) recordings from the olfactory bulb (16 channels, 1 kHz sampling rate)\n# - Sniffing signals from thermistor recordings (1 kHz sampling rate)\n# - Processed breathing event features (inhalation and exhalation times)\n# - Data from 4 subjects across 27 recording sessions\n\n# %% [markdown]\n# ## Required Packages\n# \n# The following packages are assumed to be installed:\n# - `dandi`\n# - `pynwb` \n# - `h5py`\n# - `remfile`\n# - `numpy`\n# - `matplotlib`\n# - `pandas`\n\n# %%\nimport pynwb\nimport h5py\nimport remfile\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom dandi.dandiapi import DandiAPIClient\n\n# %% [markdown]\n# ## Exploring the Dandiset with DANDI API\n\n# %%\n# Connect to the DANDI API and get dandiset metadata\nclient = DandiAPIClient()\ndandiset = client.get_dandiset(\"001433\", \"0.250507.2356\")\nmetadata = dandiset.get_raw_metadata()\n\nprint(f\"Dandiset name: {metadata['name']}\")\nprint(f\"Dandiset URL: {metadata['url']}\")\nprint(f\"Description: {metadata['description']}\")\nprint(f\"Number of subjects: {metadata['assetsSummary']['numberOfSubjects']}\")\nprint(f\"Number of files: {metadata['assetsSummary']['numberOfFiles']}\")\n\n# %% [markdown]\n# ## Exploring Available NWB Files\n\n# %%\n# Get all NWB files in the dandiset\nnwb_files = list(dandiset.get_assets_by_glob(\"*.nwb\"))\nprint(f\"Found {len(nwb_files)} NWB files\")\n\n# Display information about the files\nfor i, asset in enumerate(nwb_files[:10]):  # Show first 10 files\n    print(f\"{i+1:2d}. {asset.path}\")\n\nif len(nwb_files) > 10:\n    print(f\"    ... and {len(nwb_files) - 10} more files\")\n\n# %% [markdown]\n# ## Loading and Exploring NWB File Structure\n# \n# Let's load one representative file to understand the data structure. We'll use remote streaming to avoid downloading large files.\n\n# %%\n# Load the first NWB file using remote streaming\nasset = nwb_files[0]\nurl = asset.download_url\nremote_file = remfile.File(url)\nh5_file = h5py.File(remote_file)\nio = pynwb.NWBHDF5IO(file=h5_file)\nnwb = io.read()\n\nprint(f\"Session ID: {nwb.identifier}\")\nprint(f\"Session description: {nwb.session_description}\")\nprint(f\"Start time: {nwb.session_start_time}\")\nprint(f\"Subject ID: {nwb.subject.subject_id}\")\nprint(f\"Subject age: {nwb.subject.age}\")\nprint(f\"Subject sex: {nwb.subject.sex}\")\n\n# %% [markdown]\n# ## Examining Data Acquisition Streams\n\n# %%\n# Explore the acquisition data\nprint(\"Acquisition data streams:\")\nfor name, data in nwb.acquisition.items():\n    print(f\"  {name}: {type(data).__name__}\")\n    if hasattr(data, 'data'):\n        print(f\"    Shape: {data.data.shape}\")\n        print(f\"    Sampling rate: {data.rate} Hz\")\n        print(f\"    Description: {data.description}\")\n    print()\n\n# %% [markdown]\n# ## Examining Processed Data\n\n# %%\n# Explore the processing modules\nprint(\"Processing modules:\")\nfor module_name, module in nwb.processing.items():\n    print(f\"  {module_name}: {module.description}\")\n    print(\"    Data interfaces:\")\n    for interface_name, interface in module.data_interfaces.items():\n        print(f\"      {interface_name}: {type(interface).__name__}\")\n        if hasattr(interface, 'data'):\n            print(f\"        Shape: {interface.data.shape}\")\n            print(f\"        Description: {interface.description}\")\n    print()\n\n# %% [markdown]\n# ## Visualizing LFP Data\n# \n# Let's examine the local field potential recordings from the olfactory bulb.\n\n# %%\n# Load LFP data (sample a subset to avoid loading too much data)\nlfp = nwb.acquisition['LFP']\ntime_window = 10  # seconds\nn_samples = int(time_window * lfp.rate)\nlfp_data = lfp.data[:n_samples, :]  # First 10 seconds, all channels\ntime_axis = np.arange(n_samples) / lfp.rate\n\n# Plot LFP from multiple channels\nfig, axes = plt.subplots(4, 1, figsize=(12, 10), sharex=True)\nchannels_to_plot = [0, 4, 8, 12]  # Sample 4 channels\n\nfor i, ch in enumerate(channels_to_plot):\n    axes[i].plot(time_axis, lfp_data[:, ch], 'b-', linewidth=0.5)\n    axes[i].set_ylabel(f'Channel {ch}\\n(V)')\n    axes[i].grid(True, alpha=0.3)\n\naxes[-1].set_xlabel('Time (s)')\nplt.suptitle('Olfactory Bulb LFP Recordings (First 10 seconds)', fontsize=14)\nplt.tight_layout()\nplt.show()\n\n# %% [markdown]\n# ## Visualizing Sniffing Signal\n\n# %%\n# Load sniffing data (same time window)\nsniff = nwb.acquisition['SniffSignal']\nsniff_data = sniff.data[:n_samples]\n\n# Plot sniffing signal\nfig, ax = plt.subplots(figsize=(12, 4))\nax.plot(time_axis, sniff_data, 'r-', linewidth=1)\nax.set_xlabel('Time (s)')\nax.set_ylabel('Voltage (V)')\nax.set_title('Sniffing Signal (Thermistor)')\nax.grid(True, alpha=0.3)\nplt.tight_layout()\nplt.show()\n\n# %% [markdown]\n# ## Analyzing Breathing Events\n# \n# The dataset includes processed breathing event features. Let's examine the timing of inhalations and exhalations.\n\n# %%\n# Load breathing event data\nbehavior = nwb.processing['behavior']\ninhalation_times = behavior.data_interfaces['inhalation_time']\nexhalation_times = behavior.data_interfaces['exhalation_time']\n\n# Get event timestamps (first 1000 events to avoid loading too much)\nn_events = min(1000, len(inhalation_times.timestamps))\ninh_timestamps = inhalation_times.timestamps[:n_events]\nexh_timestamps = exhalation_times.timestamps[:n_events]\n\nprint(f\"Number of breathing events examined: {n_events}\")\nprint(f\"Recording duration: {inh_timestamps[-1]:.1f} seconds\")\n\n# %% [markdown]\n# ## Breathing Rate Analysis\n\n# %%\n# Calculate inter-breath intervals\ninter_breath_intervals = np.diff(inh_timestamps)\nbreathing_rate = 60 / inter_breath_intervals  # breaths per minute\n\n# Plot breathing rate over time\nfig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8))\n\n# Breathing rate over time\nax1.plot(inh_timestamps[1:], breathing_rate, 'g-', alpha=0.7)\nax1.set_xlabel('Time (s)')\nax1.set_ylabel('Breathing Rate (bpm)')\nax1.set_title('Breathing Rate Over Time')\nax1.grid(True, alpha=0.3)\n\n# Histogram of breathing rates\nax2.hist(breathing_rate, bins=50, alpha=0.7, color='green', edgecolor='black')\nax2.set_xlabel('Breathing Rate (bpm)')\nax2.set_ylabel('Count')\nax2.set_title('Distribution of Breathing Rates')\nax2.axvline(np.mean(breathing_rate), color='red', linestyle='--', \n           label=f'Mean: {np.mean(breathing_rate):.1f} bpm')\nax2.legend()\nax2.grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n\nprint(f\"Mean breathing rate: {np.mean(breathing_rate):.1f} \u00b1 {np.std(breathing_rate):.1f} bpm\")\n\n# %% [markdown]\n# ## Examining Breath Phase Duration\n\n# %%\n# Calculate duration of inhalation and exhalation phases\n# Note: This is a simplified calculation assuming alternating events\ninh_durations = exh_timestamps[:len(inh_timestamps)-1] - inh_timestamps[:len(inh_timestamps)-1]\nexh_durations = inh_timestamps[1:len(exh_timestamps)] - exh_timestamps[:len(exh_timestamps)-1]\n\n# Plot phase durations\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n\n# Inhalation durations\nax1.hist(inh_durations[inh_durations > 0], bins=30, alpha=0.7, color='blue', edgecolor='black')\nax1.set_xlabel('Duration (s)')\nax1.set_ylabel('Count')\nax1.set_title('Inhalation Duration Distribution')\nax1.axvline(np.mean(inh_durations[inh_durations > 0]), color='red', linestyle='--')\nax1.grid(True, alpha=0.3)\n\n# Exhalation durations  \nax2.hist(exh_durations[exh_durations > 0], bins=30, alpha=0.7, color='orange', edgecolor='black')\nax2.set_xlabel('Duration (s)')\nax2.set_ylabel('Count')\nax2.set_title('Exhalation Duration Distribution')\nax2.axvline(np.mean(exh_durations[exh_durations > 0]), color='red', linestyle='--')\nax2.grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n\n# %% [markdown]\n# ## LFP Spectral Analysis\n# \n# Let's examine the frequency content of the LFP signals to understand neural oscillations.\n\n# %%\n# Perform spectral analysis on a representative LFP channel\nfrom scipy import signal\n\n# Use a longer time window for better frequency resolution\ntime_window_spec = 60  # seconds\nn_samples_spec = int(time_window_spec * lfp.rate)\nlfp_channel = lfp.data[:n_samples_spec, 0]  # Use first channel\n\n# Compute power spectral density\nfreqs, psd = signal.welch(lfp_channel, fs=lfp.rate, nperseg=2048)\n\n# Plot power spectral density\nfig, ax = plt.subplots(figsize=(10, 6))\nax.loglog(freqs, psd)\nax.set_xlabel('Frequency (Hz)')\nax.set_ylabel('Power Spectral Density (V\u00b2/Hz)')\nax.set_title('LFP Power Spectral Density (Channel 0)')\nax.grid(True, alpha=0.3)\nax.set_xlim([1, 200])  # Focus on relevant frequency range\nplt.tight_layout()\nplt.show()\n\n# %% [markdown]\n# ## Cross-Subject Comparison\n# \n# Let's examine data from multiple subjects to understand variability.\n\n# %%\n# Load basic stats from multiple files\nsubjects_info = []\n\nfor asset in nwb_files[:6]:  # Sample first 6 files from different sessions\n    try:\n        # Load file\n        url = asset.download_url\n        remote_file = remfile.File(url)\n        h5_file = h5py.File(remote_file)\n        io = pynwb.NWBHDF5IO(file=h5_file)\n        nwb_temp = io.read()\n        \n        # Get basic information\n        subject_id = nwb_temp.subject.subject_id if nwb_temp.subject else \"Unknown\"\n        session_id = nwb_temp.identifier\n        \n        # Get breathing event count (sample first 100 events)\n        behavior_temp = nwb_temp.processing['behavior']\n        n_breathing_events = min(100, len(behavior_temp.data_interfaces['inhalation_time'].timestamps))\n        \n        subjects_info.append({\n            'subject_id': subject_id,\n            'session_id': session_id,\n            'n_breathing_events': n_breathing_events,\n            'file_path': asset.path\n        })\n        \n        # Clean up\n        io.close()\n        h5_file.close()\n        \n    except Exception as e:\n        print(f\"Error loading {asset.path}: {e}\")\n\n# Display summary\ndf = pd.DataFrame(subjects_info)\nprint(\"Summary of examined sessions:\")\nprint(df.to_string(index=False))\n\n# %% [markdown]\n# ## Summary and Future Analyses\n# \n# This dandiset provides rich simultaneous recordings of olfactory bulb LFP and breathing behavior in freely-behaving mice. Key features include:\n# \n# - **High-resolution electrophysiology**: 16-channel LFP at 1 kHz from olfactory bulb\n# - **Breathing monitoring**: Thermistor-based sniffing detection with processed event timing\n# - **Naturalistic conditions**: No task or stimuli, capturing spontaneous neural-behavioral relationships\n# \n# **Potential research directions:**\n# - Investigate coupling between breathing rhythm and neural oscillations\n# - Analyze spatial patterns of LFP activity across recording sites\n# - Examine individual differences in breathing-neural relationships\n# - Study temporal dynamics of neural-respiratory coordination\n</notebook>"
  }
]