[
  {
    "role": "system",
    "content": [
      {
        "type": "text",
        "text": "The following is metadata about Dandiset 001375 version 0.250406.1855."
      },
      {
        "type": "text",
        "text": "{\n  \"id\": \"DANDI:001375/0.250406.1855\",\n  \"doi\": \"10.48324/dandi.001375/0.250406.1855\",\n  \"url\": \"https://dandiarchive.org/dandiset/001375/0.250406.1855\",\n  \"name\": \"Septum GABA disruption with DREADDs\",\n  \"about\": [],\n  \"access\": [\n    {\n      \"status\": \"dandi:OpenAccess\",\n      \"schemaKey\": \"AccessRequirements\"\n    }\n  ],\n  \"license\": [\n    \"spdx:CC-BY-4.0\"\n  ],\n  \"version\": \"0.250406.1855\",\n  \"@context\": \"https://raw.githubusercontent.com/dandi/schema/master/releases/0.6.9/context.json\",\n  \"citation\": \"Eckert, Michael; McNaughton, Bruce; Ferbinteanu, Janina (2025) Septum GABA disruption with DREADDs (Version 0.250406.1855) [Data set]. DANDI Archive. https://doi.org/10.48324/dandi.001375/0.250406.1855\",\n  \"keywords\": [],\n  \"protocol\": [],\n  \"schemaKey\": \"Dandiset\",\n  \"identifier\": \"DANDI:001375\",\n  \"repository\": \"https://dandiarchive.org\",\n  \"contributor\": [\n    {\n      \"name\": \"Eckert, Michael\",\n      \"email\": \"meckert1@uci.edu\",\n      \"roleName\": [\n        \"dcite:ContactPerson\"\n      ],\n      \"schemaKey\": \"Person\",\n      \"affiliation\": [],\n      \"includeInCitation\": true\n    },\n    {\n      \"name\": \"NIH Brain\",\n      \"roleName\": [\n        \"dcite:Funder\"\n      ],\n      \"schemaKey\": \"Organization\",\n      \"identifier\": \"https://ror.org/05h1kgg64\",\n      \"awardNumber\": \"NS121764\",\n      \"includeInCitation\": false\n    },\n    {\n      \"name\": \"McNaughton, Bruce\",\n      \"email\": \"brucemcn@uci.edu\",\n      \"roleName\": [\n        \"dcite:Author\"\n      ],\n      \"schemaKey\": \"Person\",\n      \"includeInCitation\": true\n    },\n    {\n      \"name\": \"Ferbinteanu, Janina\",\n      \"email\": \"janina.ferbinteanu@uci.edu\",\n      \"roleName\": [\n        \"dcite:Author\"\n      ],\n      \"schemaKey\": \"Person\",\n      \"includeInCitation\": true\n    }\n  ],\n  \"dateCreated\": \"2025-04-05T16:33:36.070433+00:00\",\n  \"description\": \"Pilot study of the effect of disrupting septal gabaergic activity using DREADDs on hippocampal and neocortical activity\",\n  \"publishedBy\": {\n    \"id\": \"urn:uuid:bb8e067d-2677-42c9-aba3-245f766947ad\",\n    \"name\": \"DANDI publish\",\n    \"endDate\": \"2025-04-06T18:55:51.312365+00:00\",\n    \"schemaKey\": \"PublishActivity\",\n    \"startDate\": \"2025-04-06T18:55:51.312365+00:00\",\n    \"wasAssociatedWith\": [\n      {\n        \"id\": \"urn:uuid:7e0f6bc9-84d6-45cf-af10-2d91b72288e4\",\n        \"name\": \"DANDI API\",\n        \"version\": \"0.1.0\",\n        \"schemaKey\": \"Software\",\n        \"identifier\": \"RRID:SCR_017571\"\n      }\n    ]\n  },\n  \"studyTarget\": [],\n  \"assetsSummary\": {\n    \"species\": [\n      {\n        \"name\": \"Mus musculus - House mouse\",\n        \"schemaKey\": \"SpeciesType\",\n        \"identifier\": \"http://purl.obolibrary.org/obo/NCBITaxon_10090\"\n      }\n    ],\n    \"approach\": [\n      {\n        \"name\": \"electrophysiological approach\",\n        \"schemaKey\": \"ApproachType\"\n      }\n    ],\n    \"schemaKey\": \"AssetsSummary\",\n    \"dataStandard\": [\n      {\n        \"name\": \"Neurodata Without Borders (NWB)\",\n        \"schemaKey\": \"StandardsType\",\n        \"identifier\": \"RRID:SCR_015242\"\n      }\n    ],\n    \"numberOfBytes\": 194205289112,\n    \"numberOfFiles\": 3,\n    \"numberOfSubjects\": 2,\n    \"variableMeasured\": [\n      \"Units\",\n      \"ElectrodeGroup\"\n    ],\n    \"measurementTechnique\": [\n      {\n        \"name\": \"spike sorting technique\",\n        \"schemaKey\": \"MeasurementTechniqueType\"\n      },\n      {\n        \"name\": \"surgical technique\",\n        \"schemaKey\": \"MeasurementTechniqueType\"\n      }\n    ]\n  },\n  \"datePublished\": \"2025-04-06T18:55:51.312365+00:00\",\n  \"schemaVersion\": \"0.6.9\",\n  \"ethicsApproval\": [],\n  \"wasGeneratedBy\": [],\n  \"relatedResource\": [],\n  \"manifestLocation\": [\n    \"https://dandiarchive.s3.amazonaws.com/dandisets/001375/0.250406.1855/assets.yaml\"\n  ]\n}"
      }
    ]
  },
  {
    "role": "system",
    "content": [
      {
        "type": "text",
        "text": "The following is a listing of some of the files in the Dandiset."
      },
      {
        "type": "text",
        "text": "sub-MS13B/sub-MS13B_ses-20240725T190000_ecephys.nwb\nsub-MS14A/sub-MS14A_ses-20240906T190000_obj-12781w8_ecephys.nwb\nsub-MS14A/sub-MS14A_ses-20240906T190000_obj-ardad2_ecephys.nwb"
      }
    ]
  },
  {
    "role": "system",
    "content": [
      {
        "type": "text",
        "text": "The following is metadata and usage information about the file sub-MS13B/sub-MS13B_ses-20240725T190000_ecephys.nwb."
      },
      {
        "type": "text",
        "text": "\nimport pynwb\nimport h5py\nimport remfile\n\n# Load\nfrom dandi.dandiapi import DandiAPIClient\n\nclient = DandiAPIClient()\ndandiset = client.get_dandiset(\"001375\", \"0.250406.1855\")\nurl = next(dandiset.get_assets_by_glob(\"sub-MS13B/sub-MS13B_ses-20240725T190000_ecephys.nwb\")).download_url\n\nremote_file = remfile.File(url)\nh5_file = h5py.File(remote_file)\nio = pynwb.NWBHDF5IO(file=h5_file)\nnwb = io.read()\n\nnwb # (NWBFile)\nnwb.session_description # (str) mouse running laps in virtual hallway\nnwb.identifier # (str) MS13B\nnwb.session_start_time # (datetime) 2024-07-25T19:00:00-07:00\nnwb.timestamps_reference_time # (datetime) 2024-07-25T19:00:00-07:00\nnwb.file_create_date # (list) [datetime.datetime(2025, 4, 5, 16, 50, 15, 663983, tzinfo=tzoffset(None, -25200))]\nnwb.acquisition # (LabelledDict)\nacquisition = nwb.acquisition\ntime_series = acquisition[\"time_series\"]\ntime_series # (TimeSeries)\ntime_series.starting_time # (float64) 0.0\ntime_series.rate # (float64) 30000.0\ntime_series.resolution # (float64) -1.0\ntime_series.comments # (str) no comments\ntime_series.description # (str) no description\ntime_series.conversion # (float64) 1.0\ntime_series.offset # (float64) 0.0\ntime_series.unit # (str) mV\ntime_series.data # (Dataset) shape (144675584, 256); dtype int16\n# time_series.data[:, :] # Access all data\n# time_series.data[0:n, :] # Access first n rows\n# time_series.data[:, 0:n] # Access first n columns\ntime_series.starting_time_unit # (str) seconds\nnwb.electrode_groups # (LabelledDict)\nelectrode_groups = nwb.electrode_groups\nshank1 = electrode_groups[\"shank1\"]\nshank1 # (ElectrodeGroup)\nshank1.description # (str) shank1, electrodes\nshank1.location # (str) ventral hippocampus, visual cortex\nshank1.device # (Device)\nshank1.device.description # (str) 128 ch silicon probe\nshank1.device.manufacturer # (str) UCLA\nshank2 = electrode_groups[\"shank2\"]\nshank2 # (ElectrodeGroup)\nshank2.description # (str) shank2, electrodes\nshank2.location # (str) ventral hippocampus, visual cortex\nshank2.device # (Device)\nshank2.device.description # (str) 128 ch silicon probe\nshank2.device.manufacturer # (str) UCLA\nnwb.devices # (LabelledDict)\ndevices = nwb.devices\nsilicon_probe_array = devices[\"silicon probe array\"]\nsilicon_probe_array # (Device)\nsilicon_probe_array.description # (str) 128 ch silicon probe\nsilicon_probe_array.manufacturer # (str) UCLA\nnwb.intervals # (LabelledDict)\nintervals = nwb.intervals\ntrials = intervals[\"trials\"]\ntrials # (TimeIntervals)\ntrials.description # (str) trial start/stop times\ntrials.colnames # (tuple) ['start_time', 'stop_time']\ntrials.columns # (tuple)\ntrials.id # (ElementIdentifiers)\n# trials.to_dataframe() # (DataFrame) Convert to a pandas DataFrame with 387 rows and 2 columns\n# trials.to_dataframe().head() # (DataFrame) Show the first few rows of the pandas DataFrame\ntrials.start_time # (VectorData) start time of lap\ntrials.stop_time # (VectorData) end time of lap\nnwb.electrodes # (DynamicTable)\nnwb.electrodes.description # (str) all electrodes\nnwb.electrodes.colnames # (tuple) ['x', 'y', 'location', 'filtering', 'group', 'group_name', 'label']\nnwb.electrodes.columns # (tuple)\nnwb.electrodes.id # (ElementIdentifiers)\n# nwb.electrodes.to_dataframe() # (DataFrame) Convert to a pandas DataFrame with 256 rows and 7 columns\n# nwb.electrodes.to_dataframe().head() # (DataFrame) Show the first few rows of the pandas DataFrame\nnwb.electrodes.x # (VectorData) AUTOGENERATED description for column `x`\nnwb.electrodes.y # (VectorData) AUTOGENERATED description for column `y`\nnwb.electrodes.location # (VectorData) AUTOGENERATED description for column `location`\nnwb.electrodes.filtering # (VectorData) AUTOGENERATED description for column `filtering`\nnwb.electrodes.group # (VectorData) AUTOGENERATED description for column `group`\nnwb.electrodes.group_name # (VectorData) AUTOGENERATED description for column `group_name`\nnwb.electrodes.label # (VectorData) AUTOGENERATED description for column `label`\nnwb.subject # (Subject)\nnwb.subject.age # (str) P90D\nnwb.subject.age__reference # (str) birth\nnwb.subject.description # (str) medial septum DREADD to suppress GABA interneurons\nnwb.subject.sex # (str) M\nnwb.subject.species # (str) Mus musculus\nnwb.subject.subject_id # (str) MS13B\nnwb.trials # (TimeIntervals)\nnwb.trials.description # (str) trial start/stop times\nnwb.trials.colnames # (tuple) ['start_time', 'stop_time']\nnwb.trials.columns # (tuple)\nnwb.trials.id # (ElementIdentifiers)\n# nwb.trials.to_dataframe() # (DataFrame) Convert to a pandas DataFrame with 387 rows and 2 columns\n# nwb.trials.to_dataframe().head() # (DataFrame) Show the first few rows of the pandas DataFrame\nnwb.trials.start_time # (VectorData) start time of lap\nnwb.trials.stop_time # (VectorData) end time of lap\nnwb.units # (Units)\nnwb.units.description # (str) units table\nnwb.units.colnames # (tuple) ['spike_times']\nnwb.units.columns # (tuple)\nnwb.units.waveform_unit # (str) volts\nnwb.units.id # (ElementIdentifiers)\n# nwb.units.to_dataframe() # (DataFrame) Convert to a pandas DataFrame with 33 rows and 2 columns\n# nwb.units.to_dataframe().head() # (DataFrame) Show the first few rows of the pandas DataFrame\nnwb.units.spike_times # (VectorIndex) Index for VectorData 'spike_times'\n# nwb.units.spike_times_index[0] # (ndarray)\n# nwb.units.spike_times_index[1] # (ndarray)\n# nwb.units.spike_times_index[2] # (ndarray)\n# nwb.units.spike_times_index[3] # (ndarray)\n# ..."
      }
    ]
  },
  {
    "role": "user",
    "content": "On the basis of the above information, please create a jupytext notebook that introduces dandiset 001375 using the format described below.\n\nThe purpose of the notebook is to help researchers explore the dandiset and get started with a reanalysis.\n\nStart with an appropriate title for the notebook, such as \"Exploring Dandiset 001375: ...\" (that should be a markdown heading).\n\nInform the user that the notebook was generated with the assistance of AI, and that they should be cautious when interpreting the code or results.\n\nProvide an overview of the Dandiset. Include a link to the Dandiset of the form https://dandiarchive.org/dandiset/001375/0.250406.1855.\n\nSummarize what the notebook covers.\n\nList the packages that are required to run the notebook. Assume that these are already installed on the user's system. Do not include any pip install commands in the notebook.\n\nShow how to use the DANDI API to load assets.\n\nShow how to load and visualize data from the dandiset based on the above information. Feel free to organize things differently from how they are in the above information, but do not make up new information.\n\nGenerate good quality plots (without being redundant).\n\nLoad NWB data by streaming the remote file (as done in the above information) rather than downloading it.\n\nDo not use any functionality of pynwb or dandi that is not covered in the above information.\n\nYou should stick to material that is covered in the above information and do not hallucinate.\n\nThroughout the notebook, include explanatory markdown cells that guide the user through the process.\n\nThe notebook should be well-documented, and follow best practices Include comments in code cells to explain what each step does.\n\nThe Jupytext should use `# %% [markdown]` for markdown cells and `# %%` delimiters for the code cells.\n\nIf any NWB have units objects, you should know the following:\nunits.spike_times_index[i] provides the vector of spike times for the i^th unit. It is actually not an index. Do not use units.spike_times.\n\nYour notebook will be evaluated based on the following criteria:\n1. How well did the notebook help you understand the purpose and content of the Dandiset?\n2. After reviewing the notebook, do you feel confident in how to access the different types of data from this Dandiset?\n3. Did the notebook help you understand the structure of the NWB file(s) and how to work with them?\n4. Did the visualizations in the notebook generally help you understand key aspects of the data?\n5. Did any of the visualizations make it harder to understand the data (e.g., due to poor formatting, unclear axes, or misleading displays)?\n6. Do you feel more confident creating your own visualizations of the data after seeing the examples in the notebook?\n7. How well did the visualizations show the structure or complexity of the data?\n8. Were there any interpretations or conclusions in the notebook that felt unclear or not well supported by the data shown?\n9. Did any of the plots or examples feel unnecessarily repetitive or redundant?\n10. Did the notebook help you understand what kinds of questions or analyses you could do next with this Dandiset?\n11. How clear and easy was the notebook to follow?\n12. Did the notebook provide code you could easily reuse or adapt to explore the Dandiset yourself?\n13. Did the notebook help you understand what kinds of questions or analyses you could do next with this Dandiset?\n14. Overall, how helpful was this notebook for getting started with this Dandiset?\n\nYour output should be in the format:\n\n<notebook>\nThe text of the jupytext notebook should appear here.\n</notebook>\n\nNo other text should be included in the response.\n"
  },
  {
    "role": "assistant",
    "content": "<notebook>\n# %% [markdown]\n# # Exploring Dandiset 001375: Septum GABA Disruption with DREADDs\n#\n# *A Reanalysis Starter Notebook generated with AI assistance*\n#\n# ---\n#\n# **Caution:** This notebook was generated with the assistance of AI (GPT-4) using metadata and code patterns from Dandiset 001375. Please review all code and results carefully before relying on any interpretations or reusing code for downstream analyses.\n\n# %% [markdown]\n# ## Overview\n#\n# This notebook offers an introduction to [Dandiset 001375](https://dandiarchive.org/dandiset/001375/0.250406.1855):  \n# **\"Septum GABA disruption with DREADDs\"**.  \n#\n# This dataset presents a pilot study exploring the effects of disrupting medial septal GABAergic interneurons (via DREADDs) on hippocampal and neocortical electrophysiological activity in mice performing virtual navigation tasks.  \n#\n# The data comprises high-density electrophysiological recordings and spike sorting results, as well as trial structure and metadata in NWB format.\n#\n# ---\n#\n# **In this notebook you will learn:**\n# 1. What data are available in this Dandiset and how the NWB files are organized.\n# 2. How to access and load data from the DANDI Archive using Python, `dandi`, and `pynwb`, with examples that stream the remote file.\n# 3. How to inspect electrode, trial, and unit (spike) data.\n# 4. How to create basic visualizations of session and unit activity.\n#\n# The workflow here is intended as a starting point for more advanced reanalysis projects.\n\n# %% [markdown]\n# ## Required Packages\n#\n# This notebook requires the following Python packages (assumed already installed):\n#\n# - `dandi`\n# - `pynwb`\n# - `h5py`\n# - `remfile`\n# - `matplotlib`\n# - `pandas`\n# - `numpy`\n#\n# If you have not installed these packages, please do so before running the notebook.\n#\n# ---\n#\n# Now, let's begin by exploring the data and accessing the assets on DANDI.\n\n# %%\n# Import libraries for data access and visualization\nfrom dandi.dandiapi import DandiAPIClient\nimport pynwb\nimport h5py\nimport remfile\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\n# %% [markdown]\n# ## Connect to DANDI and List Dataset Assets\n#\n# First, let's use the DANDI API to connect to the Dandiset and list available NWB files.\n# For illustration, we'll focus on the file:  \n# `sub-MS13B/sub-MS13B_ses-20240725T190000_ecephys.nwb`\n\n# %%\n# Connect to DANDI and get the Dandiset\ndandiset_id = \"001375\"\nversion = \"0.250406.1855\"\n\nclient = DandiAPIClient()\ndandiset = client.get_dandiset(dandiset_id, version)\n\n# List all file paths in the Dandiset\nnwb_paths = [a.path for a in dandiset.get_assets() if a.path.endswith('.nwb')]\nprint(\"Available NWB files in this dandiset:\")\nfor path in nwb_paths:\n    print(\"-\", path)\n\n# %% [markdown]\n# For demonstration, we'll work with:\n#\n# `sub-MS13B/sub-MS13B_ses-20240725T190000_ecephys.nwb`\n#\n# This file contains data from mouse \"MS13B\" navigating a virtual hallway, with GABAergic neurons in the medial septum manipulated using DREADDs.\n\n# %% [markdown]\n# ## Streaming and Loading NWB Data\n#\n# To avoid large downloads, we leverage `remfile` and `h5py` to access remote NWB data streams.  \n# We'll use `pynwb.NWBHDF5IO` for high-level access.  \n# (No file will be saved to disk.)\n#\n# **Note:** This approach allows efficient inspection of large datasets.\n\n# %%\n# Get the download URL for the target NWB file\ntarget_path = \"sub-MS13B/sub-MS13B_ses-20240725T190000_ecephys.nwb\"\nasset = next(dandiset.get_assets_by_glob(target_path))\nurl = asset.download_url\n\n# Open the file stream without downloading the full file\nremote_file = remfile.File(url)\nh5_file = h5py.File(remote_file, \"r\")\nio = pynwb.NWBHDF5IO(file=h5_file, load_namespaces=True)\nnwbfile = io.read()\n\n# %% [markdown]\n# ## Session Metadata\n#\n# Let's examine some basic metadata to understand the context of the recording.\n\n# %%\n# Display session-level metadata\nprint(\"Session ID:\", nwbfile.identifier)\nprint(\"Session Start:\", nwbfile.session_start_time)\nprint(\"Session Description:\", nwbfile.session_description)\nprint(\"Subject ID:\", nwbfile.subject.subject_id)\nprint(\"Subject Species:\", nwbfile.subject.species)\nprint(\"Subject Age:\", nwbfile.subject.age)\nprint(\"Subject Sex:\", nwbfile.subject.sex)\nprint(\"Subject Description:\", nwbfile.subject.description)\n\n# %% [markdown]\n# ## Electrode Array Structure\n#\n# The NWB file describes 256 electrodes from two shanks (128 channels each) in the ventral hippocampus and visual cortex.\n#\n# Let's inspect electrode metadata.\n\n# %%\n# Convert electrode table to DataFrame and preview\nelectrodes_df = nwbfile.electrodes.to_dataframe()\nprint(f\"Electrode table shape: {electrodes_df.shape}\")\nelectrodes_df.head()\n\n# %% [markdown]\n# ### Electrode Locations by Shank\n#\n# Let's visualize the distribution of electrodes by their assigned shank (group_name) and anatomical location.\n\n# %%\n# Plot electrode counts by shank and location\nfig, ax = plt.subplots(figsize=(6,4))\nshank_counts = electrodes_df.groupby(['group_name', 'location']).size().unstack(fill_value=0)\nshank_counts.plot(kind='bar', stacked=True, ax=ax)\nax.set_ylabel('Number of Electrodes')\nax.set_title('Electrode Distribution by Shank and Location')\nplt.tight_layout()\nplt.show()\n\n# %% [markdown]\n# ## Trial Structure\n#\n# The session is organized into 387 trials, representing laps run by the mouse.  \n# We'll load the trial intervals and visualize trial durations.\n\n# %%\n# Convert trials to DataFrame\ntrials_df = nwbfile.trials.to_dataframe()\nprint(f\"Number of trials: {len(trials_df)}\")\ntrials_df.head()\n\n# %% [markdown]\n# ### Distribution of Trial Durations\n#\n# Let's visualize the spread of lap durations during the session.\n\n# %%\n# Plot histogram of trial (lap) durations\ndurations = trials_df['stop_time'] - trials_df['start_time']\nplt.figure(figsize=(6,4))\nplt.hist(durations, bins=30, color='skyblue')\nplt.xlabel('Lap Duration (s)')\nplt.ylabel('Count')\nplt.title('Distribution of Lap Durations')\nplt.show()\n\n# %% [markdown]\n# ## Raw Electrophysiology Data\n#\n# The electrophysiology data (`time_series`) contains 144,675,584 samples at 30 kHz for 256 channels.  \n# Due to file size, let's plot a short snippet from a few electrodes.\n\n# %%\n# Preview shape and dtype of raw data\nraw_data = nwbfile.acquisition['time_series'].data\nprint(\"Raw data shape:\", raw_data.shape)\nprint(\"Sampling rate:\", nwbfile.acquisition['time_series'].rate, \"Hz\")\n\n# Take a 1-second snippet from the start of 5 electrodes\nrate = int(nwbfile.acquisition['time_series'].rate)\nsnippet = raw_data[:rate, :5]  # (timepoints, 5 channels)\n\n# Plot waveforms\nplt.figure(figsize=(10,4))\nfor i in range(5):\n    plt.plot(np.arange(snippet.shape[0]) / rate, snippet[:, i] * 1e-3 + i, label=f'Chan {i}')\nplt.xlabel('Time (s)')\nplt.ylabel('Voltage + offset (mV)')\nplt.title('Raw Voltage Traces (First 5 Channels, First 1 Second)')\nplt.legend()\nplt.tight_layout()\nplt.show()\n\n# %% [markdown]\n# ## Spike Sorting Results\n#\n# The file contains 33 sorted units.  \n# Let's inspect spike count and peak firing time distributions.\n\n# %%\n# Access spike times for each unit from the units table\nunits_df = nwbfile.units.to_dataframe()\nprint(f\"Number of units: {len(units_df)}\")\nunits_df.head()\n\n# Plot histogram of spikes per unit\nspike_counts = [len(nwbfile.units.spike_times_index[i]) for i in range(len(units_df))]\nplt.figure(figsize=(6,4))\nplt.hist(spike_counts, bins=15, color='orange')\nplt.xlabel('Number of Spikes')\nplt.ylabel('Number of Units')\nplt.title('Spike Counts per Unit')\nplt.show()\n\n# %% [markdown]\n# ### Raster Plot of Example Units\n#\n# Let's visualize spike times from a subset of units as a raster plot covering the first 30 seconds of the session.\n\n# %%\n# Choose example units and plot raster for first 30 seconds\nnum_units_to_show = 8\nt_max = 30.0\n\nplt.figure(figsize=(10,4))\nfor i in range(min(num_units_to_show, len(units_df))):\n    spike_times = nwbfile.units.spike_times_index[i]\n    spike_times = np.asarray(spike_times)\n    spike_times = spike_times[(spike_times >= 0) & (spike_times <= t_max)]\n    plt.vlines(spike_times, i + 0.4, i + 0.6, color='black')\nplt.xlabel('Time (s)')\nplt.ylabel('Unit')\nplt.title('Spike Raster of First {} Units (First {} s)'.format(num_units_to_show, t_max))\nplt.yticks(range(1, num_units_to_show+1), labels=[f'Unit {i}' for i in range(num_units_to_show)])\nplt.tight_layout()\nplt.show()\n\n# %% [markdown]\n# ## Summary and Next Steps\n#\n# In this notebook, you have learned how to:\n#\n# - Access Dandiset 001375 directly from DANDI.\n# - Stream and explore NWB files (no full download required).\n# - Inspect session metadata, electrode geometry, and trial structure.\n# - Preview raw voltage data and basic sorted spike/unit information.\n# - Generate visualizations that give an overview of recording structure and data richness.\n#\n# ---\n#\n# **Possible next steps:**\n# - Align spikes to behavioral events/trials\n# - Compute firing rates or population activity\n# - Analyze spatial patterns across electrode locations\n# - Delve into detailed LFP or spike-train analyses\n#\n# Please consult the [DANDI Archive page for Dandiset 001375](https://dandiarchive.org/dandiset/001375/0.250406.1855)  \n# for more information, or adapt this code to work with other sessions/subjects in the dataset.\n#\n# ---\n#\n# _End of notebook._\n</notebook>\n"
  }
]