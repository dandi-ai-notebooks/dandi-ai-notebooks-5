[
  {
    "role": "system",
    "content": [
      {
        "type": "text",
        "text": "The following is metadata about Dandiset 001375 version 0.250406.1855."
      },
      {
        "type": "text",
        "text": "{\n  \"id\": \"DANDI:001375/0.250406.1855\",\n  \"doi\": \"10.48324/dandi.001375/0.250406.1855\",\n  \"url\": \"https://dandiarchive.org/dandiset/001375/0.250406.1855\",\n  \"name\": \"Septum GABA disruption with DREADDs\",\n  \"about\": [],\n  \"access\": [\n    {\n      \"status\": \"dandi:OpenAccess\",\n      \"schemaKey\": \"AccessRequirements\"\n    }\n  ],\n  \"license\": [\n    \"spdx:CC-BY-4.0\"\n  ],\n  \"version\": \"0.250406.1855\",\n  \"@context\": \"https://raw.githubusercontent.com/dandi/schema/master/releases/0.6.9/context.json\",\n  \"citation\": \"Eckert, Michael; McNaughton, Bruce; Ferbinteanu, Janina (2025) Septum GABA disruption with DREADDs (Version 0.250406.1855) [Data set]. DANDI Archive. https://doi.org/10.48324/dandi.001375/0.250406.1855\",\n  \"keywords\": [],\n  \"protocol\": [],\n  \"schemaKey\": \"Dandiset\",\n  \"identifier\": \"DANDI:001375\",\n  \"repository\": \"https://dandiarchive.org\",\n  \"contributor\": [\n    {\n      \"name\": \"Eckert, Michael\",\n      \"email\": \"meckert1@uci.edu\",\n      \"roleName\": [\n        \"dcite:ContactPerson\"\n      ],\n      \"schemaKey\": \"Person\",\n      \"affiliation\": [],\n      \"includeInCitation\": true\n    },\n    {\n      \"name\": \"NIH Brain\",\n      \"roleName\": [\n        \"dcite:Funder\"\n      ],\n      \"schemaKey\": \"Organization\",\n      \"identifier\": \"https://ror.org/05h1kgg64\",\n      \"awardNumber\": \"NS121764\",\n      \"includeInCitation\": false\n    },\n    {\n      \"name\": \"McNaughton, Bruce\",\n      \"email\": \"brucemcn@uci.edu\",\n      \"roleName\": [\n        \"dcite:Author\"\n      ],\n      \"schemaKey\": \"Person\",\n      \"includeInCitation\": true\n    },\n    {\n      \"name\": \"Ferbinteanu, Janina\",\n      \"email\": \"janina.ferbinteanu@uci.edu\",\n      \"roleName\": [\n        \"dcite:Author\"\n      ],\n      \"schemaKey\": \"Person\",\n      \"includeInCitation\": true\n    }\n  ],\n  \"dateCreated\": \"2025-04-05T16:33:36.070433+00:00\",\n  \"description\": \"Pilot study of the effect of disrupting septal gabaergic activity using DREADDs on hippocampal and neocortical activity\",\n  \"publishedBy\": {\n    \"id\": \"urn:uuid:bb8e067d-2677-42c9-aba3-245f766947ad\",\n    \"name\": \"DANDI publish\",\n    \"endDate\": \"2025-04-06T18:55:51.312365+00:00\",\n    \"schemaKey\": \"PublishActivity\",\n    \"startDate\": \"2025-04-06T18:55:51.312365+00:00\",\n    \"wasAssociatedWith\": [\n      {\n        \"id\": \"urn:uuid:7e0f6bc9-84d6-45cf-af10-2d91b72288e4\",\n        \"name\": \"DANDI API\",\n        \"version\": \"0.1.0\",\n        \"schemaKey\": \"Software\",\n        \"identifier\": \"RRID:SCR_017571\"\n      }\n    ]\n  },\n  \"studyTarget\": [],\n  \"assetsSummary\": {\n    \"species\": [\n      {\n        \"name\": \"Mus musculus - House mouse\",\n        \"schemaKey\": \"SpeciesType\",\n        \"identifier\": \"http://purl.obolibrary.org/obo/NCBITaxon_10090\"\n      }\n    ],\n    \"approach\": [\n      {\n        \"name\": \"electrophysiological approach\",\n        \"schemaKey\": \"ApproachType\"\n      }\n    ],\n    \"schemaKey\": \"AssetsSummary\",\n    \"dataStandard\": [\n      {\n        \"name\": \"Neurodata Without Borders (NWB)\",\n        \"schemaKey\": \"StandardsType\",\n        \"identifier\": \"RRID:SCR_015242\"\n      }\n    ],\n    \"numberOfBytes\": 194205289112,\n    \"numberOfFiles\": 3,\n    \"numberOfSubjects\": 2,\n    \"variableMeasured\": [\n      \"Units\",\n      \"ElectrodeGroup\"\n    ],\n    \"measurementTechnique\": [\n      {\n        \"name\": \"spike sorting technique\",\n        \"schemaKey\": \"MeasurementTechniqueType\"\n      },\n      {\n        \"name\": \"surgical technique\",\n        \"schemaKey\": \"MeasurementTechniqueType\"\n      }\n    ]\n  },\n  \"datePublished\": \"2025-04-06T18:55:51.312365+00:00\",\n  \"schemaVersion\": \"0.6.9\",\n  \"ethicsApproval\": [],\n  \"wasGeneratedBy\": [],\n  \"relatedResource\": [],\n  \"manifestLocation\": [\n    \"https://dandiarchive.s3.amazonaws.com/dandisets/001375/0.250406.1855/assets.yaml\"\n  ]\n}"
      }
    ]
  },
  {
    "role": "system",
    "content": [
      {
        "type": "text",
        "text": "The following is a listing of some of the files in the Dandiset."
      },
      {
        "type": "text",
        "text": "sub-MS13B/sub-MS13B_ses-20240725T190000_ecephys.nwb\nsub-MS14A/sub-MS14A_ses-20240906T190000_obj-12781w8_ecephys.nwb\nsub-MS14A/sub-MS14A_ses-20240906T190000_obj-ardad2_ecephys.nwb"
      }
    ]
  },
  {
    "role": "system",
    "content": [
      {
        "type": "text",
        "text": "The following is metadata and usage information about the file sub-MS13B/sub-MS13B_ses-20240725T190000_ecephys.nwb."
      },
      {
        "type": "text",
        "text": "\nimport pynwb\nimport h5py\nimport remfile\n\n# Load\nfrom dandi.dandiapi import DandiAPIClient\n\nclient = DandiAPIClient()\ndandiset = client.get_dandiset(\"001375\", \"0.250406.1855\")\nurl = next(dandiset.get_assets_by_glob(\"sub-MS13B/sub-MS13B_ses-20240725T190000_ecephys.nwb\")).download_url\n\nremote_file = remfile.File(url)\nh5_file = h5py.File(remote_file)\nio = pynwb.NWBHDF5IO(file=h5_file)\nnwb = io.read()\n\nnwb # (NWBFile)\nnwb.session_description # (str) mouse running laps in virtual hallway\nnwb.identifier # (str) MS13B\nnwb.session_start_time # (datetime) 2024-07-25T19:00:00-07:00\nnwb.timestamps_reference_time # (datetime) 2024-07-25T19:00:00-07:00\nnwb.file_create_date # (list) [datetime.datetime(2025, 4, 5, 16, 50, 15, 663983, tzinfo=tzoffset(None, -25200))]\nnwb.acquisition # (LabelledDict)\nacquisition = nwb.acquisition\ntime_series = acquisition[\"time_series\"]\ntime_series # (TimeSeries)\ntime_series.starting_time # (float64) 0.0\ntime_series.rate # (float64) 30000.0\ntime_series.resolution # (float64) -1.0\ntime_series.comments # (str) no comments\ntime_series.description # (str) no description\ntime_series.conversion # (float64) 1.0\ntime_series.offset # (float64) 0.0\ntime_series.unit # (str) mV\ntime_series.data # (Dataset) shape (144675584, 256); dtype int16\n# time_series.data[:, :] # Access all data\n# time_series.data[0:n, :] # Access first n rows\n# time_series.data[:, 0:n] # Access first n columns\ntime_series.starting_time_unit # (str) seconds\nnwb.electrode_groups # (LabelledDict)\nelectrode_groups = nwb.electrode_groups\nshank1 = electrode_groups[\"shank1\"]\nshank1 # (ElectrodeGroup)\nshank1.description # (str) shank1, electrodes\nshank1.location # (str) ventral hippocampus, visual cortex\nshank1.device # (Device)\nshank1.device.description # (str) 128 ch silicon probe\nshank1.device.manufacturer # (str) UCLA\nshank2 = electrode_groups[\"shank2\"]\nshank2 # (ElectrodeGroup)\nshank2.description # (str) shank2, electrodes\nshank2.location # (str) ventral hippocampus, visual cortex\nshank2.device # (Device)\nshank2.device.description # (str) 128 ch silicon probe\nshank2.device.manufacturer # (str) UCLA\nnwb.devices # (LabelledDict)\ndevices = nwb.devices\nsilicon_probe_array = devices[\"silicon probe array\"]\nsilicon_probe_array # (Device)\nsilicon_probe_array.description # (str) 128 ch silicon probe\nsilicon_probe_array.manufacturer # (str) UCLA\nnwb.intervals # (LabelledDict)\nintervals = nwb.intervals\ntrials = intervals[\"trials\"]\ntrials # (TimeIntervals)\ntrials.description # (str) trial start/stop times\ntrials.colnames # (tuple) ['start_time', 'stop_time']\ntrials.columns # (tuple)\ntrials.id # (ElementIdentifiers)\n# trials.to_dataframe() # (DataFrame) Convert to a pandas DataFrame with 387 rows and 2 columns\n# trials.to_dataframe().head() # (DataFrame) Show the first few rows of the pandas DataFrame\ntrials.start_time # (VectorData) start time of lap\ntrials.stop_time # (VectorData) end time of lap\nnwb.electrodes # (DynamicTable)\nnwb.electrodes.description # (str) all electrodes\nnwb.electrodes.colnames # (tuple) ['x', 'y', 'location', 'filtering', 'group', 'group_name', 'label']\nnwb.electrodes.columns # (tuple)\nnwb.electrodes.id # (ElementIdentifiers)\n# nwb.electrodes.to_dataframe() # (DataFrame) Convert to a pandas DataFrame with 256 rows and 7 columns\n# nwb.electrodes.to_dataframe().head() # (DataFrame) Show the first few rows of the pandas DataFrame\nnwb.electrodes.x # (VectorData) AUTOGENERATED description for column `x`\nnwb.electrodes.y # (VectorData) AUTOGENERATED description for column `y`\nnwb.electrodes.location # (VectorData) AUTOGENERATED description for column `location`\nnwb.electrodes.filtering # (VectorData) AUTOGENERATED description for column `filtering`\nnwb.electrodes.group # (VectorData) AUTOGENERATED description for column `group`\nnwb.electrodes.group_name # (VectorData) AUTOGENERATED description for column `group_name`\nnwb.electrodes.label # (VectorData) AUTOGENERATED description for column `label`\nnwb.subject # (Subject)\nnwb.subject.age # (str) P90D\nnwb.subject.age__reference # (str) birth\nnwb.subject.description # (str) medial septum DREADD to suppress GABA interneurons\nnwb.subject.sex # (str) M\nnwb.subject.species # (str) Mus musculus\nnwb.subject.subject_id # (str) MS13B\nnwb.trials # (TimeIntervals)\nnwb.trials.description # (str) trial start/stop times\nnwb.trials.colnames # (tuple) ['start_time', 'stop_time']\nnwb.trials.columns # (tuple)\nnwb.trials.id # (ElementIdentifiers)\n# nwb.trials.to_dataframe() # (DataFrame) Convert to a pandas DataFrame with 387 rows and 2 columns\n# nwb.trials.to_dataframe().head() # (DataFrame) Show the first few rows of the pandas DataFrame\nnwb.trials.start_time # (VectorData) start time of lap\nnwb.trials.stop_time # (VectorData) end time of lap\nnwb.units # (Units)\nnwb.units.description # (str) units table\nnwb.units.colnames # (tuple) ['spike_times']\nnwb.units.columns # (tuple)\nnwb.units.waveform_unit # (str) volts\nnwb.units.id # (ElementIdentifiers)\n# nwb.units.to_dataframe() # (DataFrame) Convert to a pandas DataFrame with 33 rows and 2 columns\n# nwb.units.to_dataframe().head() # (DataFrame) Show the first few rows of the pandas DataFrame\nnwb.units.spike_times # (VectorIndex) Index for VectorData 'spike_times'\n# nwb.units.spike_times_index[0] # (ndarray)\n# nwb.units.spike_times_index[1] # (ndarray)\n# nwb.units.spike_times_index[2] # (ndarray)\n# nwb.units.spike_times_index[3] # (ndarray)\n# ..."
      }
    ]
  },
  {
    "role": "user",
    "content": "On the basis of the above information, please create a jupytext notebook that introduces dandiset 001375 using the format described below.\n\nThe purpose of the notebook is to help researchers explore the dandiset and get started with a reanalysis.\n\nStart with an appropriate title for the notebook, such as \"Exploring Dandiset 001375: ...\" (that should be a markdown heading).\n\nInform the user that the notebook was generated with the assistance of AI, and that they should be cautious when interpreting the code or results.\n\nProvide an overview of the Dandiset. Include a link to the Dandiset of the form https://dandiarchive.org/dandiset/001375/0.250406.1855.\n\nSummarize what the notebook covers. This should be internally consistent with the notebook you are creating, even if it differs from what is specified in the above information.\n\nList the packages that are required to run the notebook. Assume that these are already installed on the user's system. Do not include any pip install commands in the notebook.\n\nShow how to use the DANDI Python API to information about the dandiset using code similar to the following:\n\nclient = DandiAPIClient()\ndandiset = client.get_dandiset(\"001333\", \"0.250327.2220\")\nmetadata = dandiset.get_raw_metadata()\nprint(f\"Dandiset name: {metadata['name']}\")\nprint(f\"Dandiset URL: {metadata['url']}\")\n\nShow how to use the DANDI Python API to explore the .nwb files in the dandiset.\n\nShow how to load and visualize data from the dandiset based on the above information. Feel free to organize things differently from how they are in the above information, but do not make up new information.\n\nGenerate good quality plots (without being redundant).\n\nLoad NWB data by streaming the remote file (as done in the above information) rather than downloading it.\n\nDo not use any functionality of pynwb or dandi that is not covered in the above information.\n\nYou should stick to material that is covered in the above information and do not hallucinate.\n\nThroughout the notebook, include explanatory markdown cells that guide the user through the process.\n\nThe notebook should be well-documented, and follow best practices Include comments in code cells to explain what each step does.\n\nThe Jupytext should use `# %% [markdown]` for markdown cells and `# %%` delimiters for the code cells.\n\nIf any NWB files have units objects, you should know the following:\nunits.spike_times_index[i] provides the vector of spike times for the i^th unit. It is actually not an index. Do not use units.spike_times.\n\nDo not render or display the nwb object obtained from NWBHDF5IO directly in the notebook as the output could be very large.\n\nUse concise scientific language.\n\nPrioritize correctness and accuracy over verbosity and complexity.\n\nDo not speculate about things that are not supported by the above information.\n\nSTRICT RULE: If a chat conversation is provided above, do not include new analyses that are not covered in that conversation.\n\nSTRICT RULE: If a chat conversation is provided above, you should learn from any feedback in the conversation to avoid pitfalls in plots.\n\nDo not be verbose in your summary or wrap up of the notebook, although you may briefly suggest some general ideas for future exploration.\n\nThere is no need to close files or clean up resources at the end of the notebook.\n\nYour notebook will be evaluated based on the following criteria:\n1. How well did the notebook help you understand the purpose and content of the Dandiset?\n2. After reviewing the notebook, do you feel confident in how to access the different types of data from this Dandiset?\n3. Did the notebook help you understand the structure of the NWB file(s) and how to work with them?\n4. Did the visualizations in the notebook generally help you understand key aspects of the data?\n5. Did any of the visualizations make it harder to understand the data (e.g., due to poor formatting, unclear axes, or misleading displays)?\n6. Do you feel more confident creating your own visualizations of the data after seeing the examples in the notebook?\n7. How well did the visualizations show the structure or complexity of the data?\n8. Were there any interpretations or conclusions in the notebook that felt unclear or not well supported by the data shown?\n9. Did any of the plots or examples feel unnecessarily repetitive or redundant?\n10. Did the notebook help you understand what kinds of questions or analyses you could do next with this Dandiset?\n11. How clear and easy was the notebook to follow?\n12. Did the notebook provide code you could easily reuse or adapt to explore the Dandiset yourself?\n13. Did the notebook help you understand what kinds of questions or analyses you could do next with this Dandiset?\n14. Overall, how helpful was this notebook for getting started with this Dandiset?\n\nYour output must be in the format:\n\n<notebook>\nThe text of the jupytext notebook should appear here.\n</notebook>\n\nNo other text should be included in the response.\n"
  },
  {
    "role": "assistant",
    "content": "<notebook>\n# %% [markdown]\n# # Exploring Dandiset 001375: Septum GABA Disruption with DREADDs\n\n# %% [markdown]\n# > **Note**: This notebook was generated with the assistance of AI. Please be cautious when interpreting code or results.\n\n# %% [markdown]\n# ## Overview\n# \n# This notebook explores Dandiset 001375, which contains data from a pilot study investigating the effects of disrupting septal GABAergic activity using DREADDs (Designer Receptors Exclusively Activated by Designer Drugs) on hippocampal and neocortical activity.\n# \n# Dandiset URL: [https://dandiarchive.org/dandiset/001375/0.250406.1855](https://dandiarchive.org/dandiset/001375/0.250406.1855)\n# \n# In this notebook, we will:\n# 1. Explore the metadata of the Dandiset\n# 2. List and examine the NWB files available\n# 3. Load and analyze neural recording data\n# 4. Visualize spike times and basic electrophysiological recordings\n# 5. Examine trial structure and unit activity\n\n# %% [markdown]\n# ## Required Packages\n\n# %%\n# Import necessary libraries\nimport pynwb\nimport h5py\nimport remfile\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom dandi.dandiapi import DandiAPIClient\nimport pandas as pd\n\n# %% [markdown]\n# ## Exploring Dandiset Metadata\n\n# %%\n# Initialize DandiAPI client and access the Dandiset\nclient = DandiAPIClient()\ndandiset = client.get_dandiset(\"001375\", \"0.250406.1855\")\nmetadata = dandiset.get_raw_metadata()\n\n# Display basic information about the Dandiset\nprint(f\"Dandiset name: {metadata['name']}\")\nprint(f\"Dandiset URL: {metadata['url']}\")\nprint(f\"Description: {metadata['description']}\")\nprint(f\"License: {metadata['license'][0]}\")\nprint(f\"Version: {metadata['version']}\")\n\n# %% [markdown]\n# ## Exploring Available NWB Files\n\n# %%\n# List the available NWB files in the Dandiset\nassets = list(dandiset.get_assets())\nnwb_files = [asset.path for asset in assets if asset.path.endswith('.nwb')]\n\nprint(f\"Number of NWB files: {len(nwb_files)}\")\nfor i, file in enumerate(nwb_files):\n    print(f\"{i+1}. {file}\")\n\n# %% [markdown]\n# The Dandiset contains 3 NWB files from 2 subjects. Let's examine one of these files in more detail.\n\n# %% [markdown]\n# ## Loading and Exploring an NWB File\n\n# %%\n# We'll examine the first NWB file from subject MS13B\nfile_path = \"sub-MS13B/sub-MS13B_ses-20240725T190000_ecephys.nwb\"\n\n# Get the download URL for the file\nasset = next(dandiset.get_assets_by_glob(file_path))\nurl = asset.download_url\n\n# Open the file using remfile to stream without downloading\nremote_file = remfile.File(url)\nh5_file = h5py.File(remote_file)\nio = pynwb.NWBHDF5IO(file=h5_file)\nnwb = io.read()\n\n# %% [markdown]\n# ### Basic Information about the NWB File\n\n# %%\n# Extract and display basic metadata\nprint(f\"NWB File: {file_path}\")\nprint(f\"Session Description: {nwb.session_description}\")\nprint(f\"Session Start Time: {nwb.session_start_time}\")\nprint(f\"Identifier: {nwb.identifier}\")\n\n# Subject information\nsubject = nwb.subject\nprint(\"\\nSubject Information:\")\nprint(f\"  ID: {subject.subject_id}\")\nprint(f\"  Age: {subject.age}\")\nprint(f\"  Sex: {subject.sex}\")\nprint(f\"  Species: {subject.species}\")\nprint(f\"  Description: {subject.description}\")\n\n# %% [markdown]\n# ## Electrode and Device Information\n\n# %%\n# Examine device information\ndevices = nwb.devices\nprint(\"Devices:\")\nfor device_name, device in devices.items():\n    print(f\"  {device_name}: {device.description}, Manufacturer: {device.manufacturer}\")\n\n# Examine electrode groups\nelectrode_groups = nwb.electrode_groups\nprint(\"\\nElectrode Groups:\")\nfor group_name, group in electrode_groups.items():\n    print(f\"  {group_name}: {group.description}\")\n    print(f\"    Location: {group.location}\")\n    print(f\"    Device: {group.device.description}\")\n\n# %% [markdown]\n# ### Examining Electrodes Table\n\n# %%\n# Convert electrodes to dataframe for easier exploration\nelectrodes_df = nwb.electrodes.to_dataframe()\n\n# Display basic information about electrodes\nprint(f\"Number of electrodes: {len(electrodes_df)}\")\nprint(\"First 5 electrodes:\")\ndisplay(electrodes_df.head())\n\n# Group information\nprint(\"\\nElectrode group distribution:\")\nprint(electrodes_df['group_name'].value_counts())\n\n# %% [markdown]\n# ## Neural Data Acquisition\n\n# %%\n# Examine acquisition data\nacq = nwb.acquisition['time_series']\nprint(f\"Data dimensions: {acq.data.shape}\")\nprint(f\"Sampling rate: {acq.rate} Hz\")\nprint(f\"Unit: {acq.unit}\")\nprint(f\"Data duration: {acq.data.shape[0] / acq.rate:.2f} seconds\")\n\n# %% [markdown]\n# Let's visualize a short segment of the raw electrophysiology data from a few channels:\n\n# %%\n# Plot a short segment of raw data from 4 channels\nfig, axs = plt.subplots(4, 1, figsize=(14, 10), sharex=True)\n\n# Define time window to plot (first 1 second)\ntime_window = 1  # seconds\nsample_count = int(time_window * acq.rate)\ntime_vector = np.arange(sample_count) / acq.rate\n\n# Select 4 channels to plot (from different areas if possible)\nchannels_to_plot = [0, 64, 128, 192]  # Example channels spread across the array\n\nfor i, channel in enumerate(channels_to_plot):\n    # Get channel data\n    channel_data = acq.data[:sample_count, channel]\n    \n    # Plot\n    axs[i].plot(time_vector, channel_data, linewidth=1)\n    axs[i].set_ylabel(f\"Ch {channel}\\n({acq.unit})\")\n    axs[i].grid(True, linestyle='--', alpha=0.7)\n    \n    # Add electrode location\n    electrode_info = electrodes_df.iloc[channel]\n    axs[i].set_title(f\"Channel {channel}: Group {electrode_info['group_name']}\")\n\naxs[-1].set_xlabel(\"Time (seconds)\")\nplt.suptitle(f\"Raw Electrophysiology Data - First {time_window} Second(s)\", fontsize=16)\nplt.tight_layout()\nplt.show()\n\n# %% [markdown]\n# ## Trials Information\n\n# %%\n# Examine trials information\ntrials_df = nwb.trials.to_dataframe()\nprint(f\"Number of trials: {len(trials_df)}\")\nprint(\"First 5 trials:\")\ndisplay(trials_df.head())\n\n# Calculate trial durations\ntrials_df['duration'] = trials_df['stop_time'] - trials_df['start_time']\n\n# Plot trial durations\nplt.figure(figsize=(12, 5))\nplt.plot(trials_df.index, trials_df['duration'], 'o-', alpha=0.7)\nplt.xlabel(\"Trial Number\")\nplt.ylabel(\"Duration (seconds)\")\nplt.title(f\"Trial Durations (n={len(trials_df)})\")\nplt.grid(True, linestyle='--', alpha=0.7)\nplt.show()\n\n# Distribution of trial durations\nplt.figure(figsize=(10, 5))\nplt.hist(trials_df['duration'], bins=30, alpha=0.7)\nplt.xlabel(\"Duration (seconds)\")\nplt.ylabel(\"Count\")\nplt.title(\"Distribution of Trial Durations\")\nplt.grid(True, linestyle='--', alpha=0.7)\nplt.show()\n\n# %% [markdown]\n# ## Analyzing Unit Activity\n\n# %%\n# Examine units\nunits_df = nwb.units.to_dataframe()\nprint(f\"Number of units: {len(units_df)}\")\nprint(\"Unit information:\")\ndisplay(units_df.head())\n\n# %% [markdown]\n# Let's examine the spike times for a few units:\n\n# %%\n# Plot spike raster for multiple units\nfig, ax = plt.subplots(figsize=(14, 8))\n\n# Get the first 10 units (or all if less than 10)\nnum_units_to_plot = min(10, len(units_df))\nunit_ids = list(range(num_units_to_plot))\n\n# Plot spikes for each unit\nfor i, unit_id in enumerate(unit_ids):\n    # Get spike times for this unit\n    spike_times = nwb.units.spike_times_index[unit_id]\n    \n    # Plot spike times as dots\n    ax.plot(spike_times, np.ones_like(spike_times) * i, '|', markersize=5, \n            label=f\"Unit {unit_id}\")\n\n# Customize plot\nax.set_xlabel(\"Time (seconds)\")\nax.set_ylabel(\"Unit\")\nax.set_yticks(range(num_units_to_plot))\nax.set_yticklabels([f\"Unit {i}\" for i in unit_ids])\nax.set_title(\"Spike Raster Plot\")\nax.grid(True, axis='x', linestyle='--', alpha=0.7)\n\nplt.tight_layout()\nplt.show()\n\n# %% [markdown]\n# ## Analyzing Spiking Activity During Trials\n\n# %%\n# Let's analyze the firing rate for one unit across trials\nselected_unit = 0\nspike_times = nwb.units.spike_times_index[selected_unit]\n\n# Calculate firing rates for each trial\ntrial_rates = []\ntrial_midpoints = []\n\nfor _, trial in trials_df.iterrows():\n    start = trial['start_time']\n    end = trial['stop_time']\n    duration = end - start\n    \n    # Count spikes in this trial\n    spikes_in_trial = np.sum((spike_times >= start) & (spike_times < end))\n    \n    # Calculate firing rate\n    rate = spikes_in_trial / duration\n    trial_rates.append(rate)\n    \n    # Trial midpoint for plotting\n    trial_midpoints.append((start + end) / 2)\n\n# Plot firing rates across trials\nplt.figure(figsize=(12, 5))\nplt.plot(trial_midpoints, trial_rates, 'o-', alpha=0.7)\nplt.xlabel(\"Time (seconds)\")\nplt.ylabel(\"Firing Rate (spikes/second)\")\nplt.title(f\"Unit {selected_unit} Firing Rate Across Trials\")\nplt.grid(True, linestyle='--', alpha=0.7)\nplt.show()\n\n# %% [markdown]\n# ## Visualizing Spike Waveforms in Raw Data\n\n# %%\n# Let's extract raw data around spike times to visualize average waveforms\ndef extract_waveforms(data, spike_times, sampling_rate, window_ms=2, channel=0):\n    \"\"\"Extract waveforms around spike times\"\"\"\n    samples_per_ms = sampling_rate / 1000\n    window_samples = int(window_ms * samples_per_ms)\n    \n    spike_indices = (spike_times * sampling_rate).astype(int)\n    waveforms = []\n    \n    for spike_idx in spike_indices:\n        if spike_idx - window_samples >= 0 and spike_idx + window_samples < data.shape[0]:\n            waveform = data[spike_idx - window_samples:spike_idx + window_samples, channel]\n            waveforms.append(waveform)\n            \n    return np.array(waveforms)\n\n# Select a unit and channel for visualization\nselected_unit = 0\nselected_channel = 0  # Assuming spikes are most visible on first channel\n\n# Get spike times and extract waveforms\nspike_times = nwb.units.spike_times_index[selected_unit]\n\n# Limit to first 100 spikes to avoid memory issues\nspike_times = spike_times[:100] \n\nwaveforms = extract_waveforms(acq.data, spike_times, acq.rate, window_ms=2, channel=selected_channel)\n\n# Plot average waveform with individual traces\nplt.figure(figsize=(10, 6))\ntime_ms = np.linspace(-2, 2, waveforms.shape[1])\n\n# Plot individual waveforms (semi-transparent)\nfor waveform in waveforms:\n    plt.plot(time_ms, waveform, 'k-', alpha=0.1)\n\n# Plot average waveform\nmean_waveform = np.mean(waveforms, axis=0)\nstd_waveform = np.std(waveforms, axis=0)\nplt.plot(time_ms, mean_waveform, 'r-', linewidth=2, label='Mean')\n\n# Add confidence interval\nplt.fill_between(\n    time_ms, \n    mean_waveform - std_waveform, \n    mean_waveform + std_waveform, \n    color='r', alpha=0.2, label='\u00b11 SD'\n)\n\nplt.axvline(x=0, color='gray', linestyle='--')\nplt.xlabel('Time (ms)')\nplt.ylabel(f'Amplitude ({acq.unit})')\nplt.title(f'Spike Waveforms for Unit {selected_unit} (n={len(waveforms)})')\nplt.legend()\nplt.grid(True, linestyle='--', alpha=0.7)\nplt.show()\n\n# %% [markdown]\n# ## Summary and Next Steps\n\n# %% [markdown]\n# In this notebook, we've explored Dandiset 001375, which contains electrophysiology data from mice with DREADD-mediated disruption of septal GABAergic neurons. We've examined:\n# \n# 1. The structure of the NWB files and metadata\n# 2. Electrode configuration and recording details\n# 3. Raw electrophysiological data\n# 4. Trial structures during behavioral tasks\n# 5. Unit firing patterns and waveform characteristics\n# \n# Potential future analyses could include:\n# - Cross-session comparisons of neural activity\n# - More detailed spike-train analysis (e.g., ISI distributions)\n# - Correlating neural activity with trial features\n# - Comparing activity patterns across brain regions\n</notebook>"
  }
]